#extracting mfcc for every audio file 
import librosa
filename = 'positive\damm_2.wav'
data,sample_rate = librosa.load(filename)
from scipy.io import wavfile as wav
wave_sample_rate, wave_audio = wav.read(filename)
mfccs = librosa.feature.mfcc(y=data, sr=sample_rate,n_mfcc=40)
print(mfccs.shape)
import pandas as pd
import os
audio_dataset_path_positive = 'positive'
audio_dataset_path_negative = 'negative'
def features_extractor(filename):
    audio,samplerate=librosa.load(filename)
    mfccs_features= librosa.feature.mfcc(y=audio,sr=samplerate,n_mfcc=40)
    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)
    return mfccs_scaled_features

#pip install --upgrade soundfile
#pip install --force-reinstall soundfile
import numpy as np
from tqdm import tqdm
import os
#os.chdir('C:\\Users\\VIVEK KUMAR SINGH\\Desktop\\scream detection\\positive')
#List all files in the folder
file_names = os.listdir(audio_dataset_path_positive)

# Filter out directories, leaving only file names
#file_names = [file for file in file_names if os.path.isfile(os.path.join(audio_dataset_path_positive,))]

# Print the list of file names
extracted_features=[]
for file_name in file_names:
    newname = os.path.join(os.path.relpath(audio_dataset_path_positive),file_name)
    d1 = features_extractor(newname)
    extracted_features.append([d1,"positive"])
    
f2 = os.listdir(audio_dataset_path_negative)
for file_name in f2:
    newname = os.path.join(os.path.relpath(audio_dataset_path_negative),file_name)
    d1 = features_extractor(newname)
    extracted_features.append([d1,"negative"])

extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])
extracted_features_df.head()

#splitting the dataset into independent and dependent records
X=np.array(extracted_features_df['feature'].tolist())
y=np.array(extracted_features_df['class'].tolist())

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten
from tensorflow.keras.optimizers import Adam
from sklearn import metrics
### no of classes
num_labels = y.shape[1]
#print(num_labels)

model = Sequential()
###first layer
model.add(Dense(100,input_shape=(40,)))
model.add(Activation('relu'))
model.add(Dropout(0.5))
###second layer
model.add(Dense(200))
model.add(Activation('relu'))
model.add(Dropout(0.5))
##third layer
model.add(Dense(100))
model.add(Activation('relu'))
model.add(Dropout(0.5))

### final layer 
model.add(Dense(num_labels))
model.add(Activation('sigmoid'))
model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')
from tensorflow.keras.callbacks import ModelCheckpoint
from datetime import datetime

num_epochs = 100
num_batch_size = 32

checkpointer = ModelCheckpoint(filepath='.hdf5',verbose=1,save_best_only=True)

start = datetime.now()

model.fit(X_train,y_train,batch_size=num_batch_size,epochs=num_epochs,validation_data=(X_test,y_test),callbacks=[checkpointer])
file_name = 'abuse_female_scream.wav'
newname = os.path.join(os.path.relpath(audio_dataset_path_positive),file_name)
prediction_feature = features_extractor(newname)
prediction_feature=prediction_feature.reshape(1,-1)
#model.predict_classes(prediction_feature)
predictions = (model.predict(prediction_feature) > 0.5).astype("int32")
if predictions[0][0]>predictions[0][1]:
    print("negative")
else:
    print("positive")